{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a2673b9-e833-4246-b893-4ebfab2577fe",
   "metadata": {},
   "source": [
    "# Analysis of Reddit WallStreetBets Posts: Revealing Market Trends and Investor Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6c5287-ec78-4cff-a760-06f29e111e60",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Introduction](#Introduction)\n",
    "- [Data Description](#Data-Description)\n",
    "- [Market Trends Analysis](#Market-Trends-Analysis)\n",
    "- [Investor Sentiment Analysis](#Investor-Sentiment-Analysis)\n",
    "- [Conclusion](#Conclusion)\n",
    "- [Acknowledgements](#Acknowledgements)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9e3549-cb88-43cc-a3a0-92c4b3415062",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "With the widespread use of social media, the WallStreetBets (WSB) subreddit on Reddit has become a focal point for investors worldwide. This analysis aims to study the WSB posts dataset obtained from Kaggle to reveal market trends and investor sentiment. We will focus on the following key indicators: post title (title), score (score), number of comments (comms_num), and post creation time (created)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07fc2c1-f534-4c92-8e62-740ed9c11a01",
   "metadata": {},
   "source": [
    "### import necessary python library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eb86ba2-da2b-4cd4-9b75-7eb6fb832bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cfe6081-bd84-43f3-add6-2df1fcb640b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>created</th>\n",
       "      <th>body</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's not about the money, it's about sending a...</td>\n",
       "      <td>55</td>\n",
       "      <td>l6ulcx</td>\n",
       "      <td>https://v.redd.it/6j75regs72e61</td>\n",
       "      <td>6</td>\n",
       "      <td>1.611863e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:37:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Math Professor Scott Steiner says the numbers ...</td>\n",
       "      <td>110</td>\n",
       "      <td>l6uibd</td>\n",
       "      <td>https://v.redd.it/ah50lyny62e61</td>\n",
       "      <td>23</td>\n",
       "      <td>1.611862e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:32:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Exit the system</td>\n",
       "      <td>0</td>\n",
       "      <td>l6uhhn</td>\n",
       "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
       "      <td>47</td>\n",
       "      <td>1.611862e+09</td>\n",
       "      <td>The CEO of NASDAQ pushed to halt trading â€œto g...</td>\n",
       "      <td>2021-01-28 21:30:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...</td>\n",
       "      <td>29</td>\n",
       "      <td>l6ugk6</td>\n",
       "      <td>https://sec.report/Document/0001193125-21-019848/</td>\n",
       "      <td>74</td>\n",
       "      <td>1.611862e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:28:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not to distract from GME, just thought our AMC...</td>\n",
       "      <td>71</td>\n",
       "      <td>l6ufgy</td>\n",
       "      <td>https://i.redd.it/4h2sukb662e61.jpg</td>\n",
       "      <td>156</td>\n",
       "      <td>1.611862e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-01-28 21:26:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  score      id  \\\n",
       "0  It's not about the money, it's about sending a...     55  l6ulcx   \n",
       "1  Math Professor Scott Steiner says the numbers ...    110  l6uibd   \n",
       "2                                    Exit the system      0  l6uhhn   \n",
       "3  NEW SEC FILING FOR GME! CAN SOMEONE LESS RETAR...     29  l6ugk6   \n",
       "4  Not to distract from GME, just thought our AMC...     71  l6ufgy   \n",
       "\n",
       "                                                 url  comms_num       created  \\\n",
       "0                    https://v.redd.it/6j75regs72e61          6  1.611863e+09   \n",
       "1                    https://v.redd.it/ah50lyny62e61         23  1.611862e+09   \n",
       "2  https://www.reddit.com/r/wallstreetbets/commen...         47  1.611862e+09   \n",
       "3  https://sec.report/Document/0001193125-21-019848/         74  1.611862e+09   \n",
       "4                https://i.redd.it/4h2sukb662e61.jpg        156  1.611862e+09   \n",
       "\n",
       "                                                body            timestamp  \n",
       "0                                                NaN  2021-01-28 21:37:41  \n",
       "1                                                NaN  2021-01-28 21:32:10  \n",
       "2  The CEO of NASDAQ pushed to halt trading â€œto g...  2021-01-28 21:30:35  \n",
       "3                                                NaN  2021-01-28 21:28:57  \n",
       "4                                                NaN  2021-01-28 21:26:56  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "wsb = pd.read_csv('reddit_wsb.csv')\n",
    "wsb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b20b1ef-9f3f-4c3a-b503-ffaeb5879264",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "\n",
    "First, we perform descriptive statistical analysis on the dataset to understand the basic characteristics of the posts.\n",
    "\n",
    "- Number of posts: There are 53187 posts in the dataset.\n",
    "- Score distribution: The average score of the posts is 1382, with the highest score being 348241 and the lowest score being 0.\n",
    "- Comments distribution: The average number of comments per post is 263, with the highest number of comments being 93268 and the lowest being 0.\n",
    "- Creation time distribution: The creation time span of the posts ranges from 2021-01-28 to 2021-08-02.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cce37b1-6015-4e05-8813-e1b3e2654cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53187 posts \n",
      "\n",
      "average score: 1382.461052512832 \n",
      "highest score: 348241 \n",
      "lowest score: 0 \n",
      "\n",
      "average comment number: 263.2602515652321 \n",
      "highest comment number: 93268 \n",
      "lowest comment number: 0 \n",
      "\n",
      "earliest post: 2021-01-28 21:37:41 \n",
      "newest post: 2021-08-02 12:00:14\n"
     ]
    }
   ],
   "source": [
    "print(wsb.shape[0],\"posts \\n\")\n",
    "\n",
    "print('average score:',wsb['score'].mean(),'\\n'\n",
    "      'highest score:',wsb['score'].max(), '\\n'\n",
    "      'lowest score:', wsb['score'].min(),'\\n')\n",
    "\n",
    "print('average comment number:',wsb['comms_num'].mean(),'\\n'\n",
    "     'highest comment number:',wsb['comms_num'].max(),'\\n'\n",
    "     'lowest comment number:',wsb['comms_num'].min(),'\\n')\n",
    "\n",
    "print('earliest post:',wsb.iloc[0,7],'\\n'\n",
    "      'newest post:' , wsb.iloc[-1,7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcba84a-2bd0-4a6f-80bb-0a580a166581",
   "metadata": {},
   "source": [
    "## Market Trends Analysis\n",
    "\n",
    "Next, we will analyze the market trends found within WSB posts.\n",
    "\n",
    "- Popular stocks: By counting the occurrence frequency of stock ticker symbols mentioned in post titles, we can identify the most popular stocks in the market.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b416a21f-75a4-4013-8239-bc149727efc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\", disable=[\"ner\", \"textcat\"])\n",
    "\n",
    "def process(text):\n",
    "    text = ''.join(c for c in text if c not in punctuation)\n",
    "    tokens = [token.lemma_.lower() for token in nlp(' '.join(text.split())) if token.lemma_.lower() not in nlp.Defaults.stop_words]\n",
    "    return tokens\n",
    "\n",
    "title_comb = (process(title) for title in wsb['title'])\n",
    "\n",
    "all_titles_processed = [token for title_tokens in title_comb for token in title_tokens]\n",
    "\n",
    "title_counter = Counter(all_titles_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6505591f-20c8-484f-b70c-c3cfa63fd893",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ðŸš€', 18086),\n",
       " ('gme', 8783),\n",
       " ('buy', 6274),\n",
       " ('ðŸ’Ž', 5666),\n",
       " ('hold', 5068),\n",
       " ('amc', 3492),\n",
       " ('robinhood', 3171),\n",
       " ('stock', 3095),\n",
       " ('sell', 2966),\n",
       " ('ðŸ™Œ', 2234)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1208c2-831d-4d4c-a097-055556820b93",
   "metadata": {},
   "source": [
    "By looking at the most comment list, I saw keywords like gme, amc, and robinhood. These keywords are highly related to the stock market during pandemic. Robinhood was the stock platform they used; AMC is a threater that got significantly effect by the pandemic because people don't want to get sick. GME is the stock symbol for Gamestop, which also got affected by the pandemic between 2020 to 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cef971a-4cea-4ee7-8c08-dcf91a62f46a",
   "metadata": {},
   "source": [
    "- Market sentiment: By analyzing changes in post scores and comment counts, we can gauge the overall market sentiment. For example, an increase in scores and comment counts may indicate high market sentiment, while a decrease may indicate low sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b9f2be9-63d3-42de-8c29-d15765d7c61b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market Sentiment: High \n",
      "simple average sentiment analysis score: 0.05002351702483689\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "def get_sentiment_score(text):\n",
    "    sentiment = sia.polarity_scores(text)\n",
    "    return sentiment['compound']\n",
    "wsb['sent_score'] = wsb['title'].apply(get_sentiment_score)\n",
    "mean_sentiment=wsb['sent_score'].mean()\n",
    "if mean_sentiment > 0.05:\n",
    "    market_sentiment = \"High\"\n",
    "elif mean_sentiment < -0.05:\n",
    "    market_sentiment = \"Low\"\n",
    "else:\n",
    "    market_sentiment = \"Neutral\"\n",
    "\n",
    "print(\"Market Sentiment:\", market_sentiment, '\\nsimple average sentiment analysis score:', mean_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769e017b-24f9-4def-a3dc-4b802bebe996",
   "metadata": {},
   "source": [
    "## Investor Sentiment Analysis\n",
    "\n",
    "To gain a deeper understanding of investor sentiment, we will analyze the content of WSB posts.\n",
    "\n",
    "- Keyword extraction: Using natural language processing techniques, we can extract keywords from the post bodies to reveal investors' focuses and sentiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09982782-6c3c-44e5-8a9d-6838b712af08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(text, num_keywords=5):\n",
    "\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    words = [word.lower() for word in words]\n",
    "\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered_words = [word for word in words if word.isalnum() and word not in stop_words]\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
    "\n",
    "    word_freq = Counter(stemmed_words)\n",
    "\n",
    "    # utilize TF-IDF\n",
    "    total_words = len(filtered_words)\n",
    "    keyword_scores = {word: (freq / total_words) * (np.log(total_words / (1 + word_freq[word]))) for word, freq in word_freq.items()}\n",
    "\n",
    "\n",
    "    sorted_keywords = sorted(keyword_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [word for word, score in sorted_keywords[:num_keywords]]\n",
    "wsb['keywords'] = wsb['title'].apply(lambda x: extract_keywords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b61c6fa-cc97-4064-99f6-c146af782e34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gme', 6524),\n",
       " ('buy', 3466),\n",
       " ('hold', 3456),\n",
       " ('robinhood', 2653),\n",
       " ('amc', 2596),\n",
       " ('yolo', 2007),\n",
       " ('stock', 1838),\n",
       " ('go', 1734),\n",
       " ('sell', 1703),\n",
       " ('still', 1409)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords=[keyword for kws in wsb['keywords'] for keyword in kws]\n",
    "mostkw=Counter(keywords)\n",
    "mostkw.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1204b887-e8ab-4033-9f1f-0b961885dc33",
   "metadata": {},
   "source": [
    "After we apply TFIDF methods into the title, we can see that the point I made above is very similar to here. Other than the stock vocabulary like buy, hold, stock, or sell, the rest are the main topic they are focusing on like gme, robinhood, amc, and yolo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c810cd43-7dd0-4af3-9558-2db6e673bf55",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425828bb-cf11-4fb2-872d-62db4b35a701",
   "metadata": {},
   "source": [
    "After completing an in-depth examination of Reddit WallStreetBets (WSB) posts, we have obtained valuable knowledge about market patterns and investor attitudes. The dataset from Kaggle allows us to analyze important factors like post titles, scores, comment counts, and creation times.\n",
    "\n",
    "Our results show that well-known stocks like GME, AMC, and Robinhood have been popular subjects of discussion among investors, especially in light of the pandemic. After examining fluctuations in post scores and comment counts, we have concluded that the general market sentiment is mostly positive.\n",
    "\n",
    "Moreover, our analysis of investor sentiment, employing methods such as keyword extraction and sentiment scoring using natural language processing techniques, has brought to light the key focuses and sentiments of investors. Keywords such as \"gme,\" \"buy,\" \"hold,\" \"robinhood,\" \"amc,\" and \"yolo\" have become important subjects of conversation.\n",
    "\n",
    "In short, this examination of WSB posts offers important insights for investors, analysts, and policymakers by providing a better grasp of market trends and investor attitudes. Further investigation can explore these data further to reveal more information about market dynamics and investor actions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3412e631-3bd8-4236-8f2c-acf3163f1811",
   "metadata": {},
   "source": [
    "## Acknowledgements\n",
    "\n",
    "I would like to express my gratitude to the providers of the Reddit WallStreetBets Posts dataset. This analysis would not have been possible without their valuable contribution. The dataset can be found at the following link:\n",
    "\n",
    "https://www.kaggle.com/gpreda/reddit-wallstreetsbets-posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2ec0a0-0919-4a00-9437-f1c184f958dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
